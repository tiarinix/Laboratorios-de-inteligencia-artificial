{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3\n",
    "\n",
    "## Tiara Ramírez - Valentina Cáceres\n",
    "\n",
    "## 1. Arquitectura de la CNN \n",
    "\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "En el codigo se utiliza la arquitectura de GoogLeNet (o Inception V1) que es un modelo de Deep Learning diseñado para tareas de clasificacion de imagene, que cuenta con 22 capas en total. Se cuenta con un modelo de Machine Learning mas profundo que otros anteriores, lo que implica tener más capacidad de apredizaje y, como resultado, esto aumenta el rendimiento de del modelo.  \n",
    "</p>\n",
    "\n",
    "### Modelo de Deep Learning (aprendizaje profundo): \n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "GoogLeNet tiene 22 capas profundas, pero se encuentra optimizado para reducir su complejedad utilizando bloques Inception, los cuales cuentan con una combinacion de diferentes tamaños de filtros de convolución en paralelo, como se ve en la imagen:\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Imagenes_lab3\\google-net-like.png\" width=\"40%\">\n",
    "</div>\n",
    "\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "Donde se tiene:  \n",
    "<br>\n",
    "<b>Input:</b> Corresponde una imagen de tamaño 30x30, se sabe que cuenta con 3 canales de color debido a la profundidad.   <br>\n",
    "<b>C1:</b> Corresponde a la primera capa de convolución que aplica un filtro 5x5, reduciendo el tamaño de la imagen a 28x28 con una profundidad de 10. Aquí se extraen las características básicas de cada imagen entrante, como lo son los bordes y las texturas.   <br>\n",
    "<b>P1:</b> Capa de pooling (combinación), en esta capa se reduce el tamaño utilizando un filtro de 2x2, disminuyendo a 14x14. Esta capa ayuda a reducir el número de parámetros, pero manteniendo las características más importantes. <br>\n",
    "<b>C2, C3, y C4:</b> Son capas de convolución adicionales que aplican filtros para continuar extrayendo las características más complejas en cada paso. Se puede ver cómo las dimensiones van disminuyendo de forma progresiva en cada capa, a diferencia de la profundidad, que va aumentando.   <br>\n",
    "<b>P2:</b> Segunda capa de pooling, que se encarga de disminuir el tamaño a 7x7 con una profundidad de 18 antes de entrar al bloque Inception.   <br>\n",
    "<b>Bloque Inception:</b>  Dentro de este bloque se aplican múltiples filtros de diferentes tamaños (1x1, 3x3, 5x5 y max pooling) en paralelo a la entrada. Así la red puede capturar características a diferentes escalas y niveles de detalle. Esto se puede ver de forma gráfica en la siguiente imagen.\n",
    "</p> \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Imagenes_lab3\\Incepption-module.png\" width=\"40%\">\n",
    "</div>\n",
    "\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "<b>P3: </b> Tercera capa de pooling, se encarga de reducir la dimensión espacial a 3x3, manteniendo la profundidad en 80.  <br>\n",
    "<b>M1: </b> Capa de acoplamiento (o flatten), que convierte la salida de un vector unidimensional para la capa completamente conectada.  <br>\n",
    "<b>FC (Fully Connected): </b> Capa completamente conectada que contiene 80 neuronas. Cada neura está conectada con todas las características obtenidas en los puntos anteriores.<br>\n",
    "<b>Output: </b> La salida de la red es una capa de clasificación que determina la probabilidad de cada clase  <br>\n",
    "</p> \n",
    "\n",
    "#### Modificación del modelo\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "Es necesario adaptar el modelo al problema planteado en el laboratorio, es decir a las imagenes que se deben clasifican en los 21 tipos de uso de suelo (21 clases) obtenidas de la base de datos a utilizar. La adaptación se realiza de forma simple cambiando en el codigo inferior para que la red pueda clasificar en 21 clases en lugar de las 1000 clases originales de ImageNet.<br>\n",
    "</p>\n",
    "\n",
    "### Transfer Learning \n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "El transfer learning es una técnica utilizada en el entorno de la inteligencia artificial, donde se aprovecha los pesos preentrenados de un modelo en un conjunto de datos grandes, como ImageNet, y se ajustan para resolver un problema específico con un conjunto de datos mas pequeño o diferente.<br>\n",
    "Esto tiene diversas ventajas, como lo son: aumento en la eficiencia del entrenamiento, menor necesidad de datos y unos mejores resultados en el entrenamiento. <br>\n",
    "En este caso, se utiliza un transfer learning parcial, donde se reutilizan los pesos preentrenados en las capas convolucionales de GoogLeNet, y unicamente se ajustan las capas finales del modelo para adaptarlo al problema de las 21 clases explicado con anterioridad.\n",
    "</p>\n",
    "\n",
    "### Entrenamiento del modelo\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "En este caso el modelo se entrena durante 10 épocas y en cada iteracion se guardan los parámetros ajustados. Generando 10 archivos .pth, uno por cada época, que contienen los pesos actualizados. Lo que permite realizar validaciones a modelos intermedios para determinar por ejemplo que modelo presentó el mejor desempeño, y para evitar perder el progreso si se llega a interrumpir el entrenamiento, lo que es muy util devido a lo tardado del proceso.<br>\n",
    "Se aclara ademas que en este caso la función de perdida utilizada corresponde a CrossEntropyLoss, que es la adecuada para los problemas de clasificacion con varias clases.\n",
    "</p>\n",
    "\n",
    "## 2. Entrenamiento del modelo con la base de datos de \"Uso de suelo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "error",
     "timestamp": 1730224950382,
     "user": {
      "displayName": "TIARA MARIEL RAMIREZ SABATTIN",
      "userId": "17994288330342673561"
     },
     "user_tz": 180
    },
    "id": "wKS9SfutTmlM",
    "outputId": "6199b14a-644e-414d-e548-0332cc23ef4f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# Set device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")               # Selección de la GPU\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")                               # Imprime el dispositivo seleccionado\n",
    "\n",
    "# Load pretrained GoogLeNet model\n",
    "model = models.googlenet(pretrained=True)                                           # Carga el modelo preentrenado GoogLeNet\n",
    "\n",
    "# Modify the final fully connected layer for 100 classes\n",
    "num_classes = 21                                                                    # Número de clases                      \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)                             # Modifica la capa final del modelo\n",
    "\n",
    "# Move model to the chosen device\n",
    "model = model.to(device)                                                            # Mueve el modelo a la GPU\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()                                                   # Define la función de pérdida\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)                          # Define el optimizador\n",
    "\n",
    "# Data transformations (customize as needed)\n",
    "\n",
    "    #Sin Data Augmentation\n",
    "# transform= transforms.Compose([                                                    # Transformaciones de los datos\n",
    "# transforms.Resize((224, 224)),                                                      # Redimensiona las imágenes\n",
    "# transforms.ToTensor(),                                                              # Convierte las imágenes a tensores\n",
    "# transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),        # Normaliza los tensores\n",
    "# ])\n",
    "\n",
    "    #Con Data Augmentation \n",
    "transform = transforms.Compose([                                                    # Transformaciones de los datos\n",
    "transforms.Resize((224, 224)),                                                      # Redimensiona las imágenes\n",
    "transforms.RandomHorizontalFlip(p=0.5),                                             # Voltea horizontalmente las imágenes con una probabilidad del 50%\n",
    "transforms.RandomRotation(10),                                                      # Rota las imágenes aleatoriamente en un rango de 10 grados\n",
    "transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),      # Ajusta el brillo, contraste, saturación y tono de las imágenes\n",
    "transforms.ToTensor(),                                                              # Convierte las imágenes a tensores\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),        # Normaliza los tensores\n",
    "])\n",
    "\n",
    "# Load data\n",
    "train_dataset = datasets.ImageFolder(root=\"C:\\\\Users\\\\tiari\\\\OneDrive\\\\Documents\\\\IA\\\\images_train_test_val\\\\train\", transform=transform)       # Carga el conjunto de datos de entrenamiento\n",
    "val_dataset = datasets.ImageFolder(root=\"C:\\\\Users\\\\tiari\\\\OneDrive\\\\Documents\\\\IA\\\\images_train_test_val\\\\validation\", transform=transform)    # Carga el conjunto de datos de validación\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)               # Carga el conjunto de datos de entrenamiento\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)                  # Carga el conjunto de datos de validación\n",
    "\n",
    "\n",
    "# Set up early stopping \n",
    "patience = 5\n",
    "best_loss = np.inf\n",
    "counter = 0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50                                                                     # Número de épocas\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()                                                                   # Pone el modelo en modo de entrenamiento\n",
    "    running_loss = 0.0                                                              # Inicializa \n",
    "    for images, labels in train_loader:                                             # Bucle de entrenamiento\n",
    "        images, labels = images.to(device), labels.to(device)                       # Mueve las imágenes y las etiquetas a la GPU\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)                                                     # Pasa las imágenes por el modelo\n",
    "        loss = criterion(outputs, labels)                                           # Calcula la pérdida\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()                                                       # Reinicia los gradientes\n",
    "        loss.backward()                                                             # Retropropagación\n",
    "        optimizer.step()                                                            # Actualiza los pesos\n",
    "        running_loss += loss.item()                                                 # Acumula la pérdida\n",
    "        \n",
    "    model.eval()                                                                    # Pone el modelo en modo de evaluación\n",
    "    val_loss = 0.0                                                                  # Inicializa\n",
    "    with torch.no_grad():                                                           # Desactiva el cálculo de gradientes\n",
    "        for images, labels in val_loader:                                           # Bucle de validación\n",
    "            images, labels = images.to(device), labels.to(device)                   # Mueve las imágenes y las etiquetas a la GPU\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)                                                 # Pasa las imágenes por el modelo\n",
    "            loss = criterion(outputs, labels)                                       # Calcula la pérdida\n",
    "            val_loss += loss.item()                                                 # Acumula la pérdida\n",
    "    val_loss /= len(val_loader)                                                     # Calcula la pérdida promedio\n",
    "        \n",
    "        \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {running_loss / len(train_loader):.4f}, Validation Loss: {val_loss:.4f}\", end=\"\")\n",
    "    \n",
    "    #Early stopping\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), f\"C:\\\\Users\\\\tiari\\\\OneDrive\\\\Documents\\\\IA\\\\modelos\\\\\\\\model_con_da_epoch_{epoch+1}.pth\")\n",
    "        print(\"(Guardado)\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"Stop: {counter}/{patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stop.\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Sin Data Augmentation.\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "Se comienza entrenando el modelo sin utilizar técnicas de data augmentation, por lo tanto los conjuntos de entrenamiento solo realizan las transformaciones basicas necesarias para ajustar las imagenes del conjunto de entrenamiento a lo requerido por GoogLeNet y normalizar los valores de los pixeles basados en las estadisticas del conjunto de datos ImageNet. Esto se puede observar en el codigo dedicado al entrenamiento (superior).<br>\n",
    "Obteniendo la siguiente salida al terminar el entrenamiento:\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style=\"text-align: center; line-height: 1.5;\">\n",
    "Epoch [1/50], Training Loss: 0.6966, Validation Loss: 0.5315 (Guardado)<br> \n",
    "Epoch [2/50], Training Loss: 0.2750, Validation Loss: 0.4394 (Guardado)<br>\n",
    "Epoch [3/50], Training Loss: 0.2123, Validation Loss: 0.2174 (Guardado)<br>\n",
    "Epoch [4/50], Training Loss: 0.1602, Validation Loss: 0.3055 (Stop 1/5)<br>\n",
    "Epoch [5/50], Training Loss: 0.1286, Validation Loss: 0.3191 (Stop 2/5)<br>\n",
    "Epoch [6/50], Training Loss: 0.1587, Validation Loss: 0.3480 (Stop 3/5)<br>\n",
    "Epoch [7/50], Training Loss: 0.1014, Validation Loss: 0.1829 (Guardado)<br>\n",
    "Epoch [8/50], Training Loss: 0.0998, Validation Loss: 0.0860 (Guardado)<br>\n",
    "Epoch [9/50], Training Loss: 0.0897, Validation Loss: 0.2150 (Stop 1/5)<br>\n",
    "Epoch [10/50], Training Loss: 0.0777, Validation Loss: 0.1037 (Stop 2/5)<br>\n",
    "Epoch [11/50], Training Loss: 0.0738, Validation Loss: 0.1684 (Stop 3/5)<br>\n",
    "Epoch [12/50], Training Loss: 0.0540, Validation Loss: 0.1133 (Stop 4/5)<br>\n",
    "Epoch [13/50], Training Loss: 0.0807, Validation Loss: 0.1581 (Stop 5/5)<br>\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "El entrenamiento se detuvo después de la época 13 debido a la condición de paciencia (early stopping) al alcanzar 5 iteraciones consecutivas sin mejora en la validación.<br>\n",
    "Además se puede ver a partir de la disminucion de la pérdida en cada época que el modelo es capáz de aprender representaciones utiles de cada clase de la base de datos, sin la necesidad de utilizar data augmentation. \n",
    "\n",
    "</p>\n",
    "\n",
    "### b. Con Data Augmentation\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "Para agregar tecnicas de Data Augmentation y así aumentar la robustez del modelo, se realizan diversas transformaciones (Invertir, rotar, variar brillo, color y tono), generando variaciones de las imágenes originales. Esto ayude a evitar sobreajustes y mejora la capacidad de generalización del modelo. <br>\n",
    "Obteniendo en la salida:\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: center; line-height: 1.5;\">\n",
    "Epoch [1/50], Training Loss: 0.7105, Validation Loss: 0.4326 (Guardado) <br>\n",
    "Epoch [2/50], Training Loss: 0.3750, Validation Loss: 0.3583 (Guardado)<br>\n",
    "Epoch [3/50], Training Loss: 0.2506, Validation Loss: 0.2232 (Guardado)<br>\n",
    "Epoch [4/50], Training Loss: 0.2197, Validation Loss: 0.2563 (Stop 1/5)<br>\n",
    "Epoch [5/50], Training Loss: 0.2074, Validation Loss: 0.1248 (Guardado)<br>\n",
    "Epoch [6/50], Training Loss: 0.1735, Validation Loss: 0.2542 (Stop 1/5)<br>\n",
    "Epoch [7/50], Training Loss: 0.1349, Validation Loss: 0.3105 (Stop 2/5)<br>\n",
    "Epoch [8/50], Training Loss: 0.1353, Validation Loss: 0.0885 (Guardado)<br>\n",
    "Epoch [9/50], Training Loss: 0.1225, Validation Loss: 0.1572 (Stop 1/5)<br>\n",
    "Epoch [10/50], Training Loss: 0.0991, Validation Loss: 0.1222 (Stop 2/5)<br>\n",
    "Epoch [11/50], Training Loss: 0.1040, Validation Loss: 0.1244 (Stop 3/5)<br>\n",
    "Epoch [12/50], Training Loss: 0.1321, Validation Loss: 0.1980 (Stop 4/5)<br>\n",
    "Epoch [13/50], Training Loss: 0.1106, Validation Loss: 0.2816 (Stop 5/5)<br>\n",
    "</p>\n",
    "\n",
    "\n",
    "Se puede ver que al igual en el caso anterior, durante las primeras épocas la perdida disminuye rápidamente, lo que indica que el modelo logra aprender de los datos generados, deteniendose después de la época 13 debido al criterio de paciencia (early stopping).\n",
    "\n",
    "### Comparacion de ambas técnicas.\n",
    "\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "En la tabla inferior se puede observar una comparativa de las metricas principales obtenidas del entrenamiento con y sin data augmentation, algunas observaciónes son:<br>\n",
    "<b>1- Perdida inicial:</b> Se puede ver que la perdida incial es mayor al utilizar data augmentation, que es lo esperado ya que esta técnica tiene una mayor complejidad principalmente debido a las diferentes transformaciones aplicadas a las imágenes previo al entrenamiento.<br>\n",
    "<b>2- Mejor perdida de validación:</b> Aunque la perdida de validación no es tan bajo en el caso del modelo con data augmentation en comparación, el modelo demuestra mayor capacidad de generalización y consistencia frente a los datos de validación. Ya que si bien en el caso sin data augmentation el modelo convergió rápidamente, pero hubo problemas de sobreajuste en épocas posteriores (valores de Validation Loss más altos que el esperado a pesar de la caída en Training Loss).<br>\n",
    "<b>3- Perdida final de entrenamiento:</b> En este caso el valor es nuevamente mayor con data augmentation que sin él, lo que se podría asumir como un resultado menos favorable pero esto no implica necesariamente que el modelo sea menos efectivo.<br>\n",
    "<b>4- Perdida final de validación:</b> Con data augmentation, aunque la perdida de validación no es tan baja en comparación al sin data augmentation, el modelo demuestra mayor capacidad de generalización y consistencia frente a los datos de validación.<br>\n",
    "<b>5- Variación: </b> En el caso donde se utiliza data augmentation se puede ver que las ultimas épocas presentan una pérdida mas oscilante (en ocaciones el valor de la época entrenada es superior al de la época anterior), esto se asume que es debido a que el modelo ya se está acercando al límite de su capacidad de aprendizaje para el conjunto de datos.<br>\n",
    "<b>6- Generalización: </b> En este caso como el utilizar data augmentation fuerza al modelo a aprender caracteristicas mas robustas, ya que las diferentes transformaciones realizadas en el codigo anterior hacen que las imágenes sean más variadas y menos predecibles por asi decirlo. Esto en general mejora el desempeño en los conjuntos de validación, que es una prueba que se realizará mas adelante para comprobarlo.<br>\n",
    "</p>\n",
    "\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<table>\n",
    "<tr>\n",
    "        <th>Métrica</th>\n",
    "        <th>Sin Data Augmentation</th>\n",
    "        <th>Con Data Augmentation</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Pérdida Inicial</td>\n",
    "        <td>0.6338</td>\n",
    "        <td>0.7241</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Mejor pérdida de validación</td>\n",
    "        <td>0.0860 (época 8)</td>\n",
    "        <td>0.0885 (época 8)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Pérdida Final de entrenamiento</td>\n",
    "        <td>0.0540</td>\n",
    "        <td>0.1106</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Pérdida Final de validación</td>\n",
    "        <td>0.1581</td>\n",
    "        <td>0.2816</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>Número de épocas</td>\n",
    "        <td>13</td>\n",
    "        <td>13</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Variación de Pérdida</td>\n",
    "        <td>Estable</td>\n",
    "        <td>Más oscilante</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Generalización</td>\n",
    "        <td>Menor (posible sobreajuste)</td>\n",
    "        <td>Mejor (más robusto a datos nuevos)</td>\n",
    "    </tr>\n",
    "<table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluación de métricas.\n",
    "\n",
    "### a. ¿Qué mecanismo de optimización utilizaron?\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "En esté caso se mantuvo el optimizador que ya se tenía en el codigo de referencia, que vendria siendo el optimizador <b>Adam</b> con un factor de aprendizade de 0.001. Adam es un algoritmo de optimizacion que combina las ventajas de dos diferentes optimizadores, RMSProp y SGD con momentum, ajustando dinamicamente el aprendizaje para cada parámetro en función de su gradiente.\n",
    "</p>\n",
    "\n",
    "### b. ¿Cuál es el criterio de detención del entrenamiento? \n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "Si bien el número maximo de épocas en que se puede entrenar el modelo es de 50, se tiene un mecanismo de detención temprana (early stopping) con una paciencia de 5 épocas. Esto implica que el proceso de entrenamiento se detendrá si la perdida de validación no mejora durante 5 épocas concecutivas, lo que permite optimizar el entrenamiento del modelo previendo sobreajustes innecesarios ni asignado un número insuficiente de epocas para la obtención de éste. El funcionamiento del early stoppin se pudo observar en el punto 2.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar el dispositivo (usar GPU si está disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")           # Selección de la GPU      \n",
    "print(\"Dispositivo:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")           # Imprime el dispositivo seleccionado\n",
    "\n",
    "# Cargar el modelo GoogLeNet preentrenado\n",
    "model = models.googlenet(pretrained=True)                                       # Carga el modelo preentrenado GoogLeNet\n",
    "\n",
    "# Modificar la capa totalmente conectada final para 21 clases\n",
    "num_classes = 21                                                                # Número de clases\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)                         # Modifica la capa final del modelo\n",
    "\n",
    "# Mover el modelo al dispositivo seleccionado\n",
    "model = model.to(device)                                                        # Mueve el modelo a la GPU\n",
    "\n",
    "# Cargar el mejor modelo guardado\n",
    "model_path = \"C:\\\\Users\\\\tiari\\\\OneDrive\\\\Documents\\\\IA\\\\modelos\\\\model_con_da_epoch_8.pth\"     # Ruta del archivo .pth\n",
    "model.load_state_dict(torch.load(model_path))                                   # Carga el estado del modelo\n",
    "model.eval()                                                                    # Poner el modelo en modo de evaluación\n",
    "\n",
    "# Definir las transformaciones de los datos (ajustar según sea necesario)\n",
    "transform = transforms.Compose([                                                # Transformaciones de los datos\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Cargar el conjunto de pruebas\n",
    "test_dataset = datasets.ImageFolder(root=\"C:\\\\Users\\\\tiari\\\\OneDrive\\\\Documents\\\\IA\\\\images_train_test_val\\\\test\", transform=transform)    # Carga el conjunto de prueba\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)                                                                        # Carga el conjunto de prueba en un DataLoader\n",
    "\n",
    "# Función para evaluar el modelo\n",
    "def evaluate_model(model, test_loader):                                          # Función para evaluar el modelo\n",
    "    all_labels = []                                                              # Inicializa las etiquetas verdaderas\n",
    "    all_preds = []                                                               # Inicializa las etiquetas y las predicciones\n",
    "    class_names = test_dataset.classes                                           # Obtiene los nombres de las clases\n",
    "\n",
    "    with torch.no_grad():                                                        # Deshabilita el cálculo de gradientes\n",
    "        # Bucle de evaluación\n",
    "        for images, labels in test_loader:                                    \n",
    "            images, labels = images.to(device), labels.to(device)               # Mueve las imágenes y las etiquetas a la GPU\n",
    "            outputs = model(images)                                             # Pasa las imágenes por el modelo\n",
    "            _, predicted = torch.max(outputs, 1)                                # Obtiene las predicciones\n",
    "            all_labels.extend(labels.cpu().numpy())                             # Añade las etiquetas verdaderas\n",
    "            all_preds.extend(predicted.cpu().numpy())                           # Añade las predicciones\n",
    "\n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(all_labels, all_preds)                                            # Calcula la matriz de confusión\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_dataset.classes) # Configura la visualización\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)                                        # Visualiza la matriz de confusión\n",
    "    plt.title(\"Matriz de confusión\")                                                        # Título de la visualización\n",
    "    plt.show()                                                                              # Muestra la visualización\n",
    "    \n",
    "    # Indicadores de rendimiento\n",
    "    print(\"\\n Indicadores de rendimiento:\")\n",
    "    report = classification_report(\n",
    "        all_labels, \n",
    "        all_preds, \n",
    "        target_names=class_names,\n",
    "        digits=4,\n",
    "    )\n",
    "    print(report)                                                                           # Imprime los indicadores de rendimiento\n",
    "    \n",
    "# Evaluar el modelo\n",
    "evaluate_model(model, test_loader)                                                # Evalúa el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Matriz de confusión e indicadores de desempeño\n",
    "\n",
    "#### Sin data augmentation:\n",
    "La matriz de confusion al evaluar el mejor modelo obtenido con data augmentation es la siguiente:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Imagenes_lab3\\matriz.png\" width=\"40%\">\n",
    "</div>\n",
    "\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "La matriz muestra valores máximos de 50 en la diagonal principal (predicciones correctas por clase), indicando que el modelo identificó correctamente un número significativo de imágenes por clase. Las confusiones son mínimas y están principalmente distribuidas entre clases con caractéristicas visuales similares. <br>\n",
    "Estos valores demuestran que el modelo es robusto, incluso en clases más desafiantes.\n",
    " \n",
    "\n",
    "Los ingicadores evaluados (precision, recall y F1-score) son por clase y muestran los siguientes resultados para los 21 clases:  <br>\n",
    "1. Precisión: Mide la proporción de predicciones correctas por clase respecto al total de predicciones hechas para esa clase. En este caso se obtuvo una media y macro ponderada de 0.9757  <br>\n",
    "2. Sensibilidad (Recall): Mide la proporción de predicciones correctas para una clase respecto al total de muestras reales de esa clase. La media macro y ponderada fue de un 0.9752<br>\n",
    "3. F1-score: Es la media armónica entre precisión y sensibilida, proporcionando un balance entre ambas métricas. La media y macro ponderada fue de 0.9752<br>\n",
    "4. Exactitud global (Accuracy): El modelo logró una exactitud de 97.52% en el conjunto de prueba.<br>\n",
    "</p>\n",
    "\n",
    "\n",
    "Indicadores de rendimiento:\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Clase</th>\n",
    "            <th>Precision</th>\n",
    "            <th>Recall</th>\n",
    "            <th>F1-Score</th>\n",
    "            <th>Support</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>agricultural</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>airplane</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>baseballdiamond</td>\n",
    "            <td>0.9792</td>\n",
    "            <td>0.9400</td>\n",
    "            <td>0.9592</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>beach</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>buildings</td>\n",
    "            <td>0.9592</td>\n",
    "            <td>0.9400</td>\n",
    "            <td>0.9495</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>chaparral</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>denseresidential</td>\n",
    "            <td>0.9796</td>\n",
    "            <td>0.9600</td>\n",
    "            <td>0.9697</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>forest</td>\n",
    "            <td>0.9804</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>0.9901</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>freeway</td>\n",
    "            <td>0.9615</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>0.9804</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>golfcourse</td>\n",
    "            <td>0.9231</td>\n",
    "            <td>0.9600</td>\n",
    "            <td>0.9412</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>harbor</td>\n",
    "            <td>0.9804</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>0.9901</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>intersection</td>\n",
    "            <td>0.9245</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>0.9515</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>mediumresidential</td>\n",
    "            <td>0.9216</td>\n",
    "            <td>0.9400</td>\n",
    "            <td>0.9307</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>mobilehomepark</td>\n",
    "            <td>0.9615</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>0.9804</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>overpass</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>0.9899</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>parkinglot</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>river</td>\n",
    "            <td>0.9787</td>\n",
    "            <td>0.9200</td>\n",
    "            <td>0.9485</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>runway</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>sparseresidential</td>\n",
    "            <td>0.9796</td>\n",
    "            <td>0.9600</td>\n",
    "            <td>0.9697</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>storagetanks</td>\n",
    "            <td>1.0000</td>\n",
    "            <td>0.9400</td>\n",
    "            <td>0.9691</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tenniscourt</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>0.9800</td>\n",
    "            <td>50</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Overall</strong></td>\n",
    "            <td>0.9757</td>\n",
    "            <td>0.9752</td>\n",
    "            <td>0.9752</td>\n",
    "            <td>1050</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "A partir de la tabla se pueden tener algunas observaciones respecto a los resultados:\n",
    "1. El desempeño es consistente entre clases debido al buen ajuste del modelo y el uso de GoogLeNet preentrenado, optimizado con Adam y un criterio de detención adecuado.\n",
    "2. Las clases como parkinglot, runway y chaparral lograron un F1-score perfecto, mientras que clases como golfcourse y mediumresidential tienen valores ligeramente más bajos. Esto podría ser porque estas clases comparten carácteristicas visuales con otras categorias, lo que complica su clasificación.\n",
    "3. A pesar de no utilizar data augmentation, el modelo logró un desempeño sobresaliente. Esto sugiere que el conjunto de datos de entrenamiento tiene buena diversidad y calidad, proporcionando suficiente informacion para generalizar.\n",
    "\n",
    "#### Con data augmentation:\n",
    "\n",
    "Se obtuvo la siguiente matriz de confusión al probar el codigo con data augmentation\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Imagenes_lab3\\matriz con da.png\" width=\"40%\">\n",
    "</div>\n",
    "\n",
    "Se puede ver que en este caso aunque se introduce mas variabilidad en los datos en el momento del entrenamiento, también genera ligeros errores en clases que previamente tenían un desempeño perfecto, como lo son las clases de tenniscourt y storagetanks que muestran ligeras reducciones en recall y presición con data augmentation.\n",
    "\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Clase</th>\n",
    "      <th>Precisión</th>\n",
    "      <th>Recall</th>\n",
    "      <th>F1-Score</th>\n",
    "      <th>Support</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><td>agricultural</td><td>1.0000</td><td>1.0000</td><td>1.0000</td><td>50</td></tr>\n",
    "    <tr><td>airplane</td><td>1.0000</td><td>0.9800</td><td>0.9899</td><td>50</td></tr>\n",
    "    <tr><td>baseballdiamond</td><td>1.0000</td><td>0.9600</td><td>0.9796</td><td>50</td></tr>\n",
    "    <tr><td>beach</td><td>0.9796</td><td>0.9600</td><td>0.9697</td><td>50</td></tr>\n",
    "    <tr><td>buildings</td><td>0.9388</td><td>0.9200</td><td>0.9293</td><td>50</td></tr>\n",
    "    <tr><td>chaparral</td><td>1.0000</td><td>1.0000</td><td>1.0000</td><td>50</td></tr>\n",
    "    <tr><td>denseresidential</td><td>0.8727</td><td>0.9600</td><td>0.9143</td><td>50</td></tr>\n",
    "    <tr><td>forest</td><td>0.9245</td><td>0.9800</td><td>0.9515</td><td>50</td></tr>\n",
    "    <tr><td>freeway</td><td>0.9259</td><td>1.0000</td><td>0.9615</td><td>50</td></tr>\n",
    "    <tr><td>golfcourse</td><td>0.9796</td><td>0.9600</td><td>0.9697</td><td>50</td></tr>\n",
    "    <tr><td>harbor</td><td>1.0000</td><td>1.0000</td><td>1.0000</td><td>50</td></tr>\n",
    "    <tr><td>intersection</td><td>0.8929</td><td>1.0000</td><td>0.9434</td><td>50</td></tr>\n",
    "    <tr><td>mediumresidential</td><td>1.0000</td><td>0.8200</td><td>0.9011</td><td>50</td></tr>\n",
    "    <tr><td>mobilehomepark</td><td>1.0000</td><td>0.9600</td><td>0.9796</td><td>50</td></tr>\n",
    "    <tr><td>overpass</td><td>0.9583</td><td>0.9200</td><td>0.9388</td><td>50</td></tr>\n",
    "    <tr><td>parkinglot</td><td>1.0000</td><td>1.0000</td><td>1.0000</td><td>50</td></tr>\n",
    "    <tr><td>river</td><td>0.9608</td><td>0.9800</td><td>0.9703</td><td>50</td></tr>\n",
    "    <tr><td>runway</td><td>0.9804</td><td>1.0000</td><td>0.9901</td><td>50</td></tr>\n",
    "    <tr><td>sparseresidential</td><td>0.9800</td><td>0.9800</td><td>0.9800</td><td>50</td></tr>\n",
    "    <tr><td>storagetanks</td><td>0.9216</td><td>0.9400</td><td>0.9307</td><td>50</td></tr>\n",
    "    <tr><td>tenniscourt</td><td>1.0000</td><td>0.9600</td><td>0.9796</td><td>50</td></tr>\n",
    "  </tbody>\n",
    "  <tfoot>\n",
    "    <tr>\n",
    "      <td><strong>Overall</strong></td>\n",
    "      <td>0.9674</td>\n",
    "      <td>0.9657</td>\n",
    "      <td>0.9657</td>\n",
    "      <td>1050</td>\n",
    "    </tr>\n",
    "  </tfoot>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "Al observar los datos de la tabla se pueden ver pequeñas diferencias con respecto al modelo sin data augmentation, que se profundizan en los siguientes puntos:\n",
    "1. Precision (97.52% sin da y 96.57% con da): Aunque la precisión global con data augmentation es ligeramente menor, este resultado no necesariamente indica un empeoramiento, ya que el data augmentation tiende a mejorar la capacidad de generalizacion del modelo en datos no vistos.\n",
    "2. Recall y F1-score: En general el data augmentation no impactó de forma significativa en las clases que ya tenian un desempeño perfecto o casi perfecto, pero podría haber mejorado la generalización para las clases más dificiles en un conjunto diferente de validación.\n",
    "3. El uso de data augmentation introduce variaciones en las imágenes de entrenamiento, como rotaciones, reflejos y cambios de color, que buscan simular imagenes que no se encuentren en el conjunto de entrenamiento pero si en el mundo real. Esto en general es útil para mejorar la robustez del modelo pero en este caso puede haber causado una ligera disminucion del desempeño. Esto se puede atibuir tanto a un posible sobreentrenamiento del modelo o a que los datos de prueba no eran los suficientemente variado para reflejar de forma adecuada los escenarios para los que fue entrenado el modelo con las técnicas de data augmentation. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prueba de los modelos con imagenese de Google Earth Engine (GEE).\n",
    "\n",
    "Se obtienen 10 imagenes utilizando google earth, para ello se seleccionarion diferentes puntos de la región metropolitana y sus alrededores, teniendo en concreto las siguientes imagenes:\n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: center;\">\n",
    "\n",
    "<img src=\"Imagenes_lab3\\google\\1.png\" alt=\"Imagen 1\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\2.png\" alt=\"Imagen 2\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\3.png\" alt=\"Imagen 3\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\4.png\" alt=\"Imagen 4\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\5.png\" alt=\"Imagen 5\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\6.png\" alt=\"Imagen 6\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\7.png\" alt=\"Imagen 7\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\8.png\" alt=\"Imagen 8\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\9.png\" alt=\"Imagen 9\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\google\\10.png\" alt=\"Imagen 9\" width=\"300\" style=\"margin: 5px;\">\n",
    "\n",
    "</div>\n",
    "\n",
    "Luego se realiza la clasificiación de cada imagen utilizando tanto el modelo sin data augmentation como con data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from collections import Counter\n",
    "\n",
    "# Ruta de la carpeta de imágenes\n",
    "Image_folder = \"C:\\\\Users\\\\tiari\\\\OneDrive\\\\Documents\\\\IA\\\\Laboratorios-de-inteligencia-artificial\\\\Imagenes_lab3\\\\google\"\n",
    "\n",
    "# Transformaciones de los datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Función para cargar imágenes de una carpeta\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    file_names = []\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".png\"):\n",
    "            img = Image.open(os.path.join(folder, file))\n",
    "            img = img.convert(\"RGB\")  # Convert image to RGB\n",
    "            img = transform(img)\n",
    "            images.append(img)\n",
    "            file_names.append(file)\n",
    "    return images, file_names\n",
    "\n",
    "# Cargar las imágenes de la carpeta\n",
    "images, file_names = load_images_from_folder(Image_folder)\n",
    "\n",
    "# Selección de la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar el modelo preentrenado GoogLeNet\n",
    "model = models.googlenet(pretrained=True)\n",
    "num_classes = 21\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"C:\\\\Users\\\\tiari\\\\OneDrive\\\\Documents\\\\IA\\\\modelos\\\\model_sin_da_epoch_8.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Inicializa la lista de predicciones\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for img in images:\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        output = model(img)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predictions.append(predicted.item())\n",
    "\n",
    "# Nombres de las clases\n",
    "class_names = [\n",
    "    'agricultural', 'airplane', 'baseballdiamond', 'beach', 'buildings',\n",
    "    'chaparral', 'denseresidential', 'forest', 'freeway', 'golfcourse',\n",
    "    'harbor', 'intersection', 'mediumresidential', 'mobilehomepark', 'overpass',\n",
    "    'parkinglot', 'river', 'runway', 'sparseresidential', 'storagetanks', 'tenniscourt'\n",
    "]\n",
    "\n",
    "# Cuenta las predicciones por clase\n",
    "class_counts = {class_name: predictions.count(i) for i, class_name in enumerate(class_names)}\n",
    "total_images = len(predictions)\n",
    "\n",
    "# Calcula el porcentaje de predicciones por clase\n",
    "class_percentages = Counter(predictions)\n",
    "top_5_classes = sorted(class_percentages.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Porcentajes de las 5 clases con mayor representación\n",
    "top_5_percentages = [(class_names[class_id], count / total_images * 100) for class_id, count in top_5_classes]\n",
    "print(\"Porcentajes de las 5 clases con mayor representación:\")\n",
    "for class_name, percentage in top_5_percentages:\n",
    "    print(f\"{class_name}: {percentage:.2f}%\")\n",
    "\n",
    "# Diccionario con las etiquetas verdaderas\n",
    "true_labels = {\n",
    "    \"1.png\": \"agricultural\",\n",
    "    \"2.png\": \"denseresidential\",\n",
    "    \"3.png\": \"sparseresidential\",\n",
    "    \"4.png\": \"chaparral\",\n",
    "    \"5.png\": \"airplane\",\n",
    "    \"6.png\": \"overpass\",\n",
    "    \"7.png\": \"river\",\n",
    "    \"8.png\": \"tenniscourt\",\n",
    "    \"9.png\": \"forest\",\n",
    "    \"10.png\": \"agricultural\",\n",
    "}\n",
    "\n",
    "# Calcular el porcentaje de acierto\n",
    "correct_predictions = 0\n",
    "total_images = len(images)\n",
    "\n",
    "results = []\n",
    "for i, file_name in enumerate(file_names):\n",
    "    predicted_class = class_names[predictions[i]]\n",
    "    true_class = true_labels[file_name]\n",
    "    is_correct = predicted_class == true_class\n",
    "    correct_predictions += is_correct\n",
    "    results.append((file_name, true_class, predicted_class, is_correct))\n",
    "\n",
    "accuracy = correct_predictions / total_images * 100\n",
    "print(f\"Porcentaje de acierto del modelo: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Predicciones por clase:\")\n",
    "\n",
    "for file_name, true_class, predicted_class, is_correct in results:\n",
    "    print(f\"Imagen: {file_name}, Clase verdadera: {true_class}, Predicción: {predicted_class}, Correcta: {is_correct}\")\n",
    "    \n",
    "# Mostrar las imágenes con sus predicciones\n",
    "for i, (image, file_name) in enumerate(zip(images, file_names)):\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Predicción: {class_names[predictions[i]]}\\nVerdadera: {true_labels[file_name]}\", fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Con data augmentation\n",
    "\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "Se comienza realizando la clasificación utilizando el modelo sin data augmentation, obteniendo:<br>\n",
    "\n",
    "<b> Porcentajes de las 5 clases con mayor representación:</b>\n",
    "- overpass: 30.00%\n",
    "- tenniscourt: 20.00%\n",
    "- chaparral: 20.00%\n",
    "- baseballdiamond: 10.00%\n",
    "- denseresidential: 10.00%<br>\n",
    "\n",
    "<b> Porcentaje de acierto del modelo: </b> 40.00%\n",
    "\n",
    "<b>Predicciones por clase:</b>\n",
    "\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Imagen</th>\n",
    "      <th>Clase Verdadera</th>\n",
    "      <th>Predicción</th>\n",
    "      <th>Correcta</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>agricultural</td>\n",
    "      <td>overpass</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>agricultural</td>\n",
    "      <td>baseballdiamond</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>denseresidential</td>\n",
    "      <td>denseresidential</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>sparseresidential</td>\n",
    "      <td>tenniscourt</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>chaparral</td>\n",
    "      <td>chaparral</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>airplane</td>\n",
    "      <td>buildings</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>overpass</td>\n",
    "      <td>overpass</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>river</td>\n",
    "      <td>overpass</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>8</td>\n",
    "      <td>tenniscourt</td>\n",
    "      <td>tenniscourt</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td>forest</td>\n",
    "      <td>chaparral</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "<b> Inspección visual: </b>  \n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: center;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\1.png\" alt=\"Imagen 1\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\2.png\" alt=\"Imagen 2\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\3.png\" alt=\"Imagen 3\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\4.png\" alt=\"Imagen 4\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\5.png\" alt=\"Imagen 5\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\6.png\" alt=\"Imagen 6\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\7.png\" alt=\"Imagen 7\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\8.png\" alt=\"Imagen 8\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\9.png\" alt=\"Imagen 9\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_sin_da\\10.png\" alt=\"Imagen 9\" width=\"300\" style=\"margin: 5px;\">\n",
    "</div>\n",
    "\n",
    "#### Sin data augmentation\n",
    "\n",
    "<p style=\"text-align: justify; line-height: 1.5;\">\n",
    "<b> Porcentajes de las 5 clases con mayor representación (predicción):</b>\n",
    "\n",
    "- runway: 20.00%\n",
    "- denseresidential: 20.00%\n",
    "- chaparral: 20.00%\n",
    "- sparseresidential: 10.00%\n",
    "- buildings: 10.00%\n",
    "\n",
    "<b> Porcentaje de acierto del modelo: </b> 50.00%<br>\n",
    "<b> Predicciones por clase:</b>\n",
    "</p>\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Imagen</th>\n",
    "      <th>Clase Verdadera</th>\n",
    "      <th>Predicción</th>\n",
    "      <th>Correcta</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>agricultural</td>\n",
    "      <td>runway</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>agricultural</td>\n",
    "      <td>runway</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>denseresidential</td>\n",
    "      <td>denseresidential</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>sparseresidential</td>\n",
    "      <td>sparseresidential</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>chaparral</td>\n",
    "      <td>chaparral</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>airplane</td>\n",
    "      <td>buildings</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>overpass</td>\n",
    "      <td>overpass</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>river</td>\n",
    "      <td>denseresidential</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>8</td>\n",
    "      <td>tenniscourt</td>\n",
    "      <td>tenniscourt</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td>forest</td>\n",
    "      <td>chaparral</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</div>\n",
    "\n",
    "<b> Inspección visual:</b>\n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: center;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\1.png\" alt=\"Imagen 1\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\2.png\" alt=\"Imagen 2\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\3.png\" alt=\"Imagen 3\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\4.png\" alt=\"Imagen 4\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\5.png\" alt=\"Imagen 5\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\6.png\" alt=\"Imagen 6\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\7.png\" alt=\"Imagen 7\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\8.png\" alt=\"Imagen 8\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\9.png\" alt=\"Imagen 9\" width=\"300\" style=\"margin: 5px;\">\n",
    "<img src=\"Imagenes_lab3\\Class_con_da\\10.png\" alt=\"Imagen 9\" width=\"300\" style=\"margin: 5px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "##### Comparativa de los resultados entregados por ambos modelos.\n",
    "\n",
    "- Se puede ver como a pesar de que en las pruebas realizadas anteriormente el modelo con data augmentation parecia ser peor, en este caso aumento el porcentaje de acierto en un 10% (40% a 50%). Esto sugiere que la diversidad introducida en los datos mejora la capacidad del modelo para generalizar y enfrentarce a clasificar imagenes mas desafiantes, sobretodo teniendo en cuenta que era muy dificil que cualquier modelo fuese capaz de detectar al rio mapocho como rio por ejemplo.<br>\n",
    "- En cuanto a la distribución de los errores, algunos persistieron con o sin data augmentation, lo que podría indicar limitaciones en las carácteristicas aprendidas por el modelo o en la representacion de estas clases en el conjunto de datos original. Por ejemplo en la imagen del aeropuerto ningún modelo es capaz de detectar los aviones, lo que se asume que es debido a que igual se presentan edificios en la imagen y los modelos estaban entrenados para detectar los aviones a una mayor cercania.<br>\n",
    "- Se pudo ver tambien como las clases de chaparral y tenniscourt tuvieron un buen desempeño con ambos modelos, lo que sugiere que estas clases tienen patrones mas distintivos. A diferencia de las clases como agricultural y river que confunden al modelo con otras visualmente similares (runway y denseresidential)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
